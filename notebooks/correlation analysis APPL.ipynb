{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693751cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\yohanan\\price-prediction-from-news-sentiment\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\yohanan\\price-prediction-from-news-sentiment\\.venv\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\yohanan\\price-prediction-from-news-sentiment\\.venv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yohanan\\price-prediction-from-news-sentiment\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yohanan\\price-prediction-from-news-sentiment\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yohanan\\price-prediction-from-news-sentiment\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Yohanan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yohanan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yohanan\\price-prediction-from-news-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(news_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].dt, \u001b[33m'\u001b[39m\u001b[33mtz\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (news_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].dt.tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m news_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.contains(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[+-]\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m'\u001b[39m).any()):\n\u001b[32m     35\u001b[39m \tnews_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = news_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].dt.tz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m merged_df = \u001b[43malign_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m analyze_correlation(merged_df)\n\u001b[32m     38\u001b[39m calculate_sentiment(news_df)  \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yohanan\\price-prediction-from-news-sentiment\\scripts\\correlation.py:19\u001b[39m, in \u001b[36malign_data\u001b[39m\u001b[34m(news_df, stock_df)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Convert dates to datetime format\u001b[39;00m\n\u001b[32m     18\u001b[39m news_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(news_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m]).dt.date\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m stock_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mstock_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m).dt.date\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Group news by date and calculate average sentiment\u001b[39;00m\n\u001b[32m     22\u001b[39m daily_sentiment = news_df.groupby(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m).apply(calculate_sentiment).reset_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yohanan\\price-prediction-from-news-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yohanan\\price-prediction-from-news-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'date'"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "import sys\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "# If scripts.correlation is not found, ensure the scripts directory is in the sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Use the known correlation_path variable to add the scripts directory to sys.path\n",
    "scripts_dir = os.path.dirname(correlation_path)\n",
    "if scripts_dir not in sys.path:\n",
    "\tsys.path.insert(0, scripts_dir)\n",
    "\n",
    "if not os.path.exists(correlation_path):\n",
    "\traise FileNotFoundError(f\"Could not find '{correlation_path}'. Please ensure 'correlation.py' exists in the 'scripts' directory one level above your current working directory.\")\n",
    "\n",
    "try:\n",
    "\tfrom correlation import align_data, analyze_correlation, calculate_sentiment, interpret_correlation, plot_correlation\n",
    "except ModuleNotFoundError:\n",
    "\traise ModuleNotFoundError(\"Could not import 'correlation'. Make sure 'correlation.py' exists in the scripts directory and is accessible.\")\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "# Use the already loaded news_df and stock_df variables from the notebook\n",
    "# Ensure 'date' column is in datetime format and handle missing values\n",
    "news_df= pd.read_csv('data/raw_analyst_ratings.csv')\n",
    "stock_df = pd.read_csv('data/yfinance_data/AAPL_historical_data.csv')\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce')\n",
    "news_df = news_df.dropna(subset=['date'])\n",
    "# Remove timezone info if present\n",
    "if hasattr(news_df['date'].dt, 'tz') and (news_df['date'].dt.tz is not None or news_df['date'].astype(str).str.contains(r'[+-]\\d{2}:\\d{2}').any()):\n",
    "\tnews_df['date'] = news_df['date'].dt.tz_localize(None)\n",
    "merged_df = align_data(news_df, stock_df)\n",
    "analyze_correlation(merged_df)\n",
    "calculate_sentiment(news_df)  \n",
    "interpret_correlation(news_df, stock_df)\n",
    "plot_correlation(news_df, stock_df)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
